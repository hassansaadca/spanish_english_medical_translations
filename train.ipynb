{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 44031,
     "status": "ok",
     "timestamp": 1658334865575,
     "user": {
      "displayName": "Hassan Saad",
      "userId": "01133516266367700533"
     },
     "user_tz": 420
    },
    "id": "XSAi2tu382kO",
    "outputId": "0ff04f2b-27b3-4451-c453-51f672e6d850"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.20.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.7.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.11.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.8.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.8.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.9)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (1.11.0)\n",
      "Requirement already satisfied: typing_extensions in /opt/conda/lib/python3.7/site-packages (from torch) (4.2.0)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.7/site-packages (2.3.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from datasets) (1.19.5)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from datasets) (4.11.4)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets) (3.8.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.8.1)\n",
      "Requirement already satisfied: dill<0.3.6 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.3.5.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from datasets) (3.0.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets) (0.70.13)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2022.5.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (8.0.0)\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.3.5)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.7/site-packages (from datasets) (4.64.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.2.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->datasets) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (3.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (21.4.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.7.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (0.13.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets) (3.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2022.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (0.1.96)\n",
      "Requirement already satisfied: transformers[sentencepiece] in /opt/conda/lib/python3.7/site-packages (4.20.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers[sentencepiece]) (2.28.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers[sentencepiece]) (0.12.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers[sentencepiece]) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers[sentencepiece]) (4.64.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers[sentencepiece]) (4.11.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers[sentencepiece]) (3.7.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers[sentencepiece]) (21.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers[sentencepiece]) (2022.7.9)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers[sentencepiece]) (1.19.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers[sentencepiece]) (0.8.1)\n",
      "Requirement already satisfied: protobuf<=3.20.1 in /opt/conda/lib/python3.7/site-packages (from transformers[sentencepiece]) (3.20.1)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /opt/conda/lib/python3.7/site-packages (from transformers[sentencepiece]) (0.1.96)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers[sentencepiece]) (4.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers[sentencepiece]) (3.0.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers[sentencepiece]) (3.8.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers[sentencepiece]) (2022.6.15)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers[sentencepiece]) (2.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers[sentencepiece]) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers[sentencepiece]) (3.3)\n",
      "Requirement already satisfied: sacrebleu in /opt/conda/lib/python3.7/site-packages (2.1.0)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.7/site-packages (from sacrebleu) (0.4.5)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.7/site-packages (from sacrebleu) (0.8.10)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.7/site-packages (from sacrebleu) (2022.7.9)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from sacrebleu) (1.19.5)\n",
      "Requirement already satisfied: portalocker in /opt/conda/lib/python3.7/site-packages (from sacrebleu) (2.5.1)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (0.0.53)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from sacremoses) (4.64.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses) (8.1.3)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.7/site-packages (from sacremoses) (2022.7.9)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses) (1.16.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses) (1.1.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click->sacremoses) (4.11.4)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses) (4.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses) (3.8.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip install transformers \n",
    "# !pip install torch \n",
    "# !pip install datasets \n",
    "# !pip install sentencepiece \n",
    "# !pip install transformers[sentencepiece] \n",
    "# !pip install sacrebleu \n",
    "# !pip install sacremoses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 10139,
     "status": "ok",
     "timestamp": 1658334875710,
     "user": {
      "displayName": "Hassan Saad",
      "userId": "01133516266367700533"
     },
     "user_tz": 420
    },
    "id": "tfTa7xrmkoJE"
   },
   "outputs": [],
   "source": [
    "# from google.colab import auth, drive\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer, Trainer, TrainingArguments\n",
    "from datasets import load_metric\n",
    "\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 892,
     "status": "ok",
     "timestamp": 1658334999135,
     "user": {
      "displayName": "Hassan Saad",
      "userId": "01133516266367700533"
     },
     "user_tz": 420
    },
    "id": "BMkE4ACqFDG2",
    "outputId": "b11fe87c-82e4-4183-b5a4-0e6018825386",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "790915 data/UFAL/medical.all\n",
      "711824 data/UFAL/medical.train_val\n",
      "79091 data/UFAL/medical.test\n"
     ]
    }
   ],
   "source": [
    "!wc -l data/UFAL/medical.all\n",
    "!wc -l data/UFAL/medical.train_val\n",
    "!wc -l data/UFAL/medical.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1658335282870,
     "user": {
      "displayName": "Hassan Saad",
      "userId": "01133516266367700533"
     },
     "user_tz": 420
    },
    "id": "JBOTZgd0NRih"
   },
   "outputs": [],
   "source": [
    "SOURCE_LANGUAGE = 'es'\n",
    "TARGET_LANGUAGE = 'en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "executionInfo": {
     "elapsed": 176,
     "status": "ok",
     "timestamp": 1658336966869,
     "user": {
      "displayName": "Hassan Saad",
      "userId": "01133516266367700533"
     },
     "user_tz": 420
    },
    "id": "WdnKg81yeOOf"
   },
   "outputs": [],
   "source": [
    "def load_model(source_language, target_language):\n",
    "  model_checkpoint = f\"Helsinki-NLP/opus-mt-{source_language}-{target_language}\"\n",
    "  tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "  model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
    "  print(f'Model Checkpoint Name: {model_checkpoint}')\n",
    "  lang = {'es':'Spanish', 'en':'English'}\n",
    "  print(f'Translation: {lang[source_language]} to {lang[target_language]}')\n",
    "  return tokenizer, model, model_checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4246,
     "status": "ok",
     "timestamp": 1658336971833,
     "user": {
      "displayName": "Hassan Saad",
      "userId": "01133516266367700533"
     },
     "user_tz": 420
    },
    "id": "Qs_Snp5_jqv9",
    "outputId": "a947cc98-3eeb-4ee8-adbb-b0467277ab52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Checkpoint Name: Helsinki-NLP/opus-mt-es-en\n",
      "Translation: Spanish to English\n"
     ]
    }
   ],
   "source": [
    "tokenizer, model, model_checkpoint = load_model(source_language = SOURCE_LANGUAGE, target_language = TARGET_LANGUAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "executionInfo": {
     "elapsed": 199,
     "status": "ok",
     "timestamp": 1658337951194,
     "user": {
      "displayName": "Hassan Saad",
      "userId": "01133516266367700533"
     },
     "user_tz": 420
    },
    "id": "X3y9tRNvIjCb"
   },
   "outputs": [],
   "source": [
    "def load_data(source_language, corpus = 'data/UFAL/medical.train_val'):\n",
    "\n",
    "  with open(corpus) as f:\n",
    "    l = f.readlines()\n",
    "  \n",
    "  pairs = []\n",
    "  for i in l:\n",
    "      pairs.append(i.strip().split('\\t'))\n",
    "\n",
    "  total_lines = len(l)\n",
    "  split = int(total_lines * .8)\n",
    "\n",
    "  if source_language == 'es':\n",
    "    train_sources= [i[0] for i in pairs[0:split]] \n",
    "    train_targets = [i[1] for i in pairs[0:split]]\n",
    "    val_sources = [i[0] for i in pairs[split:]]\n",
    "    val_targets = [i[1] for i in pairs[split:]]\n",
    "  else:\n",
    "    train_sources= [i[1] for i in pairs[-1:-1* split:-1]] \n",
    "    train_targets = [i[0] for i in pairs[-1:-1* split:-1]]\n",
    "    val_sources = [i[1] for i in pairs[-1*split::-1]]\n",
    "    val_targets = [i[0] for i in pairs[-1*split::-1]]\n",
    "\n",
    "  print('Sample Sources:\\n----------')\n",
    "  for i in train_sources[:2]:\n",
    "    print(i)\n",
    "  print('\\nSample Targets:\\n----------')\n",
    "  for i in train_targets[:2]:\n",
    "    print(i)\n",
    "  return train_sources, train_targets, val_sources, val_targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3808,
     "status": "ok",
     "timestamp": 1658337955174,
     "user": {
      "displayName": "Hassan Saad",
      "userId": "01133516266367700533"
     },
     "user_tz": 420
    },
    "id": "2B62UaMmglBT",
    "outputId": "db4d3743-038a-4bf8-e7f4-80cd5459b2c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Sources:\n",
      "----------\n",
      "Poco frecuentes\n",
      "Lietuva Merck Serono Atstovybė C/ o Ares Trading SA Baltic States Zamenhofo 11-3, LT-44287 Kaunas Tel: +370 37320603\n",
      "\n",
      "Sample Targets:\n",
      "----------\n",
      "Uncommon\n",
      "256 Lietuva Merck Serono Atstovybė C/ o Ares Trading SA Baltic States Zamenhofo 11-3, LT-44287 Kaunas Tel: +370 37320603\n"
     ]
    }
   ],
   "source": [
    "train_sources, train_targets, val_sources, val_targets = load_data(source_language = SOURCE_LANGUAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "executionInfo": {
     "elapsed": 161,
     "status": "ok",
     "timestamp": 1658337279729,
     "user": {
      "displayName": "Hassan Saad",
      "userId": "01133516266367700533"
     },
     "user_tz": 420
    },
    "id": "LRfJKGVCFDG4"
   },
   "outputs": [],
   "source": [
    "assert len(train_targets)==len(train_sources)\n",
    "assert len(val_targets)==len(val_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1658337023975,
     "user": {
      "displayName": "Hassan Saad",
      "userId": "01133516266367700533"
     },
     "user_tz": 420
    },
    "id": "TOfdkeMe8t1P"
   },
   "outputs": [],
   "source": [
    "class BatchData(torch.utils.data.Dataset):\n",
    "    def __init__(self, source_texts, target_texts, tokenizer, max_length= 512):\n",
    "        self.source_texts = source_texts\n",
    "        self.target_texts = target_texts\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_token_length = max_length\n",
    "\n",
    "\n",
    "    def convert_data(self):\n",
    "        self.model_inputs = self.tokenizer(self.source_texts, max_length = self.max_token_length, truncation = True) #, padding = True)\n",
    "        with tokenizer.as_target_tokenizer():\n",
    "            self.labels = tokenizer(self.target_texts, max_length= self.max_token_length, truncation = True) #, padding = True)\n",
    "        self.model_inputs['labels'] = self.labels['input_ids']\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.model_inputs.items()}\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.model_inputs['labels'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1658337352909,
     "user": {
      "displayName": "Hassan Saad",
      "userId": "01133516266367700533"
     },
     "user_tz": 420
    },
    "id": "Uc4Q9KxS9Bh1"
   },
   "outputs": [],
   "source": [
    "train_dataset = BatchData(train_sources, train_targets, tokenizer = tokenizer)\n",
    "val_dataset = BatchData(val_sources, val_targets, tokenizer = tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "executionInfo": {
     "elapsed": 219684,
     "status": "ok",
     "timestamp": 1658337572785,
     "user": {
      "displayName": "Hassan Saad",
      "userId": "01133516266367700533"
     },
     "user_tz": 420
    },
    "id": "4gF-teGKLGVb"
   },
   "outputs": [],
   "source": [
    "train_dataset.convert_data()\n",
    "val_dataset.convert_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1658337213436,
     "user": {
      "displayName": "Hassan Saad",
      "userId": "01133516266367700533"
     },
     "user_tz": 420
    },
    "id": "nxZd2OhMXL78"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1658337573318,
     "user": {
      "displayName": "Hassan Saad",
      "userId": "01133516266367700533"
     },
     "user_tz": 420
    },
    "id": "xV5gJJl8Ic1b"
   },
   "outputs": [],
   "source": [
    "assert len(train_dataset) == len(train_sources)\n",
    "assert len(val_dataset) == len(val_sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 177,
     "status": "ok",
     "timestamp": 1658337627907,
     "user": {
      "displayName": "Hassan Saad",
      "userId": "01133516266367700533"
     },
     "user_tz": 420
    },
    "id": "poTJ816ELOjN",
    "outputId": "bc15e684-571c-4df3-f328-21a389318cc8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fine-tuned Model Directory:\n",
      "opus-mt-es-en-finetuned-es-to-en/\n"
     ]
    }
   ],
   "source": [
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "\n",
    "\n",
    "\n",
    "#https://huggingface.co/docs/transformers/main_classes/trainer\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    f\"{model_name}-finetuned-{SOURCE_LANGUAGE}-to-{TARGET_LANGUAGE}\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    save_steps = 50,\n",
    "    num_train_epochs=1,\n",
    "    predict_with_generate=True   \n",
    ")\n",
    "\n",
    "print('\\nFine-tuned Model Directory:')\n",
    "print(f\"{model_name}-finetuned-{SOURCE_LANGUAGE}-to-{TARGET_LANGUAGE}/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "d5d1a67ce71d4dada33345986c77ca6c",
      "c15e3c9f1b2c4d2ca4f9aef41f795099",
      "41f5591f06184b5cadccfd6bdb44551f",
      "2210968aca73433488029438b96c4727",
      "b4debbd240cb410f982c78b250693861",
      "6a21b2cf77e742f6802c8d61e065fbde",
      "fbc852c874494647b4c3f41b1b44c58c",
      "972e98eaa8d2497e9cf13eb8f03ce136",
      "20f20386cdd24fc292846ab0c0bb18d5",
      "236695886c8a4a319ea4357c0463fe29",
      "8550569b00194c3b9ee410872633fc7b"
     ]
    },
    "executionInfo": {
     "elapsed": 417,
     "status": "ok",
     "timestamp": 1658337689002,
     "user": {
      "displayName": "Hassan Saad",
      "userId": "01133516266367700533"
     },
     "user_tz": 420
    },
    "id": "CO4fnHCLLRDE",
    "outputId": "2220c986-fb3a-4930-cccd-f96f7e8247d4"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5d1a67ce71d4dada33345986c77ca6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/2.85k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "metric = load_metric(\"sacrebleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1658337689003,
     "user": {
      "displayName": "Hassan Saad",
      "userId": "01133516266367700533"
     },
     "user_tz": 420
    },
    "id": "7R38znbULS2U"
   },
   "outputs": [],
   "source": [
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [[label.strip()] for label in labels]\n",
    "    return preds, labels\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    # Some simple post-processing\n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    result = {\"bleu\": result[\"score\"]}\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    result = {k: round(v, 4) for k, v in result.items()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1658337690804,
     "user": {
      "displayName": "Hassan Saad",
      "userId": "01133516266367700533"
     },
     "user_tz": 420
    },
    "id": "6I65y6imLYOL"
   },
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 645
    },
    "executionInfo": {
     "elapsed": 1260073,
     "status": "ok",
     "timestamp": 1658263124771,
     "user": {
      "displayName": "Hassan Saad",
      "userId": "01133516266367700533"
     },
     "user_tz": 420
    },
    "id": "LJDvXY7wLcke",
    "outputId": "583cb855-dd84-4069-a08f-a52541ace947"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 800\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 100\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 20:49, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Bleu</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.123492</td>\n",
       "      <td>13.912100</td>\n",
       "      <td>28.075000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to opus-mt-en-es-finetuned-en-to-es/checkpoint-50\n",
      "Configuration saved in opus-mt-en-es-finetuned-en-to-es/checkpoint-50/config.json\n",
      "Model weights saved in opus-mt-en-es-finetuned-en-to-es/checkpoint-50/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-es-finetuned-en-to-es/checkpoint-50/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-es-finetuned-en-to-es/checkpoint-50/special_tokens_map.json\n",
      "Saving model checkpoint to opus-mt-en-es-finetuned-en-to-es/checkpoint-100\n",
      "Configuration saved in opus-mt-en-es-finetuned-en-to-es/checkpoint-100/config.json\n",
      "Model weights saved in opus-mt-en-es-finetuned-en-to-es/checkpoint-100/pytorch_model.bin\n",
      "tokenizer config file saved in opus-mt-en-es-finetuned-en-to-es/checkpoint-100/tokenizer_config.json\n",
      "Special tokens file saved in opus-mt-en-es-finetuned-en-to-es/checkpoint-100/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 200\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=100, training_loss=3.4800796508789062, metrics={'train_runtime': 1259.7788, 'train_samples_per_second': 0.635, 'train_steps_per_second': 0.079, 'total_flos': 18654693949440.0, 'train_loss': 3.4800796508789062, 'epoch': 1.0})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l83usu2Xo8cz"
   },
   "source": [
    "## Import Fine-Tuned Model and Compare with Baseline\n",
    "\n",
    "Fine-Tuned Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4451,
     "status": "ok",
     "timestamp": 1658265199201,
     "user": {
      "displayName": "Hassan Saad",
      "userId": "01133516266367700533"
     },
     "user_tz": 420
    },
    "id": "gW7zJxidRwGF",
    "outputId": "fdcc7a9b-989c-4a71-c1af-91e2ba6305b2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Didn't find file opus-mt-en-es-finetuned-en-to-es/checkpoint-100/target_vocab.json. We won't load it.\n",
      "Didn't find file opus-mt-en-es-finetuned-en-to-es/checkpoint-100/added_tokens.json. We won't load it.\n",
      "loading file opus-mt-en-es-finetuned-en-to-es/checkpoint-100/source.spm\n",
      "loading file opus-mt-en-es-finetuned-en-to-es/checkpoint-100/target.spm\n",
      "loading file opus-mt-en-es-finetuned-en-to-es/checkpoint-100/vocab.json\n",
      "loading file None\n",
      "loading file opus-mt-en-es-finetuned-en-to-es/checkpoint-100/tokenizer_config.json\n",
      "loading file None\n",
      "loading file opus-mt-en-es-finetuned-en-to-es/checkpoint-100/special_tokens_map.json\n",
      "loading configuration file opus-mt-en-es-finetuned-en-to-es/checkpoint-100/config.json\n",
      "Model config MarianConfig {\n",
      "  \"_name_or_path\": \"Helsinki-NLP/opus-mt-en-es\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"swish\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"MarianMTModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bad_words_ids\": [\n",
      "    [\n",
      "      65000\n",
      "    ]\n",
      "  ],\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 512,\n",
      "  \"decoder_attention_heads\": 8,\n",
      "  \"decoder_ffn_dim\": 2048,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 65000,\n",
      "  \"decoder_vocab_size\": 65001,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 8,\n",
      "  \"encoder_ffn_dim\": 2048,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 0,\n",
      "  \"extra_pos_embeddings\": 65001,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_length\": 512,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"marian\",\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 65000,\n",
      "  \"scale_embedding\": true,\n",
      "  \"share_encoder_decoder_embeddings\": true,\n",
      "  \"static_position_embeddings\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65001\n",
      "}\n",
      "\n",
      "loading weights file opus-mt-en-es-finetuned-en-to-es/checkpoint-100/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing MarianMTModel.\n",
      "\n",
      "All the weights of MarianMTModel were initialized from the model checkpoint at opus-mt-en-es-finetuned-en-to-es/checkpoint-100.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use MarianMTModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "last_epoch = 100\n",
    "\n",
    "tuned_model_name = f'opus-mt-en-es-finetuned-en-to-es/checkpoint-{last_epoch}'\n",
    "tokenizer = MarianTokenizer.from_pretrained(tuned_model_name)\n",
    "model = MarianMTModel.from_pretrained(tuned_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gZwaRVPkrb_-"
   },
   "outputs": [],
   "source": [
    "src_txt = ['Of these, 51% had generalised peritonitis at baseline.']\n",
    "\n",
    "#correct translation: De estos, el 51% presentaba peritonitis generalizada en el momento basal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1079,
     "status": "ok",
     "timestamp": 1658263281907,
     "user": {
      "displayName": "Hassan Saad",
      "userId": "01133516266367700533"
     },
     "user_tz": 420
    },
    "id": "Qp4LeGLnsypZ",
    "outputId": "4df28e49-b476-4972-867a-96db23ff9922"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['De ellos, el 51% tenía peritonitis generalizada al inicio.']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated = model.generate(**tokenizer(src_txt, return_tensors=\"pt\", padding=True))\n",
    "[tokenizer.decode(t, skip_special_tokens=True) for t in translated]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1E2ICZsIO5tR"
   },
   "source": [
    "Compare to Base Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6TPH5oUUNTZn"
   },
   "outputs": [],
   "source": [
    "base_model_name = f\"Helsinki-NLP/opus-mt-{source_language}-{target_language}\"\n",
    "base_tokenizer = MarianTokenizer.from_pretrained(base_model_name)\n",
    "base_model = MarianMTModel.from_pretrained(base_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1011,
     "status": "ok",
     "timestamp": 1658263789010,
     "user": {
      "displayName": "Hassan Saad",
      "userId": "01133516266367700533"
     },
     "user_tz": 420
    },
    "id": "4vdr9_LpNf5G",
    "outputId": "66131773-f009-4ad4-9948-11ea61007f29"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['De ellos, el 51% tenía peritonitis generalizada al inicio.']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated = base_model.generate(**tokenizer(src_txt, return_tensors=\"pt\", padding=True))\n",
    "[base_tokenizer.decode(t, skip_special_tokens=True) for t in translated]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "train.ipynb",
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-11.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-11:m94"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "20f20386cdd24fc292846ab0c0bb18d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2210968aca73433488029438b96c4727": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_236695886c8a4a319ea4357c0463fe29",
      "placeholder": "​",
      "style": "IPY_MODEL_8550569b00194c3b9ee410872633fc7b",
      "value": " 7.65k/? [00:00&lt;00:00, 144kB/s]"
     }
    },
    "236695886c8a4a319ea4357c0463fe29": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "41f5591f06184b5cadccfd6bdb44551f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_972e98eaa8d2497e9cf13eb8f03ce136",
      "max": 2848,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_20f20386cdd24fc292846ab0c0bb18d5",
      "value": 2848
     }
    },
    "6a21b2cf77e742f6802c8d61e065fbde": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8550569b00194c3b9ee410872633fc7b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "972e98eaa8d2497e9cf13eb8f03ce136": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b4debbd240cb410f982c78b250693861": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c15e3c9f1b2c4d2ca4f9aef41f795099": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6a21b2cf77e742f6802c8d61e065fbde",
      "placeholder": "​",
      "style": "IPY_MODEL_fbc852c874494647b4c3f41b1b44c58c",
      "value": "Downloading builder script: "
     }
    },
    "d5d1a67ce71d4dada33345986c77ca6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c15e3c9f1b2c4d2ca4f9aef41f795099",
       "IPY_MODEL_41f5591f06184b5cadccfd6bdb44551f",
       "IPY_MODEL_2210968aca73433488029438b96c4727"
      ],
      "layout": "IPY_MODEL_b4debbd240cb410f982c78b250693861"
     }
    },
    "fbc852c874494647b4c3f41b1b44c58c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
